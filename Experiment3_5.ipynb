{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eacab2fe",
   "metadata": {},
   "source": [
    "### Motivation:\n",
    "what do we plan to do here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "522d415f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd50a7864d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060daa4e",
   "metadata": {},
   "source": [
    "#### Description:\n",
    "Number of images (both in test and train folder) = 384 <br>\n",
    "**MatchNumbersTable.npz** file contains number of matches between every pair of images\n",
    "```python\n",
    "    MatchNumbersTable.npz file size = (384,384)\n",
    "    \n",
    "    array([[   0.,  711., 1009., ...,  107.,  300.,  447.],\n",
    "           [ 711.,    0.,  951., ...,  161.,  150.,  120.],\n",
    "           [1008.,  950.,    0., ...,  199.,  484.,  572.],\n",
    "           ...,\n",
    "           [ 107.,  161.,  199., ...,    0.,  592.,  580.],\n",
    "           [ 300.,  150.,  484., ...,  592.,    0., 1074.],\n",
    "           [ 447.,  120.,  572., ...,  580., 1074.,    0.]])\n",
    "```\n",
    "***\n",
    "- In **2D_list_of_all_npzs_with_class.npz** file\n",
    "    - shape = ( 384 , 385 )\n",
    "    - first 384 column = the path of npz file between the current image and every other images<br>\n",
    "    - last column = class name of the current image\n",
    "```python\n",
    "    array([['',\n",
    "        'Experiment2/All_npzs/10429168_D_lowres_10428972_D_lowres_matches.npz',\n",
    "        'Experiment2/All_npzs/10429168_D_lowres_10429194_D_lowres_matches.npz',\n",
    "        ...,\n",
    "        'Experiment2/All_npzs/10429168_D_lowres_10429013_D_lowres_matches.npz',\n",
    "        'Experiment2/All_npzs/10429168_D_lowres_10429016_D_lowres_matches.npz',\n",
    "        'erato_petiverana'],\n",
    "        ...,\n",
    "        ['Experiment2/All_npzs/10429016_D_lowres_10429168_D_lowres_matches.npz',\n",
    "        'Experiment2/All_npzs/10429016_D_lowres_10428972_D_lowres_matches.npz',\n",
    "        'Experiment2/All_npzs/10429016_D_lowres_10429194_D_lowres_matches.npz',\n",
    "        ...,\n",
    "        'Experiment2/All_npzs/10429016_D_lowres_10429013_D_lowres_matches.npz',\n",
    "        '', 'erato_notabilis']], dtype='<U100')\n",
    "```\n",
    "***\n",
    "- **class_names** = set of all classes in the dataset\n",
    "- **class_name_of_each_rowImg** = list of class name of every row image (384,1)\n",
    "- **number_of_matches_between_every_image_with_className** = number of matches + class name of that image (384, 385)\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc595550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a table, \n",
    "#where each row contains information [match# with img1] [match# with img2] [match# with img384] [Class Name of this row]\n",
    "path = 'Experiment2/MatchNumbersTable.npz'\n",
    "number_of_matches_between_every_image = np.load(path)['arr_0']\n",
    "TotalImage=number_of_matches_between_every_image.shape[0]\n",
    "\n",
    "path = 'Experiment2/2D_list_of_all_npzs_with_class.npz'\n",
    "name_of_npzfile_between_each_pair_with_className_of_rowImg = np.load(path)['arr_0']\n",
    "class_name_of_each_rowImg=name_of_npzfile_between_each_pair_with_className_of_rowImg[:,TotalImage]\n",
    "\n",
    "class_names=list(set(class_name_of_each_rowImg))\n",
    "class_name_of_each_rowImg=np.reshape(class_name_of_each_rowImg,(TotalImage,1))\n",
    "number_of_matches_between_every_image_with_className=np.append(number_of_matches_between_every_image,class_name_of_each_rowImg,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8330db19",
   "metadata": {},
   "source": [
    "- **function create_dataset_wrt_k**\n",
    "    - k = number of top matches for every class for the current image to consider\n",
    "    - creates X \n",
    "        - size ( 384, 27) = (Number of images, Number of class)\n",
    "        - per image, take average number of matches for every class\n",
    "    - create Y\n",
    "        - size (384, 1) = (Number of images, class name of the image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "493ff373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_wrt_k(k_given,percentage,number_of_matches_between_every_image_with_className,class_names,class_name_of_each_rowImg):\n",
    "    \n",
    "    k=k_given\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    TotalImage=number_of_matches_between_every_image_with_className.shape[0]\n",
    "\n",
    "    for mainImgNumber in range(TotalImage):\n",
    "        x=[]\n",
    "        for currentClassName in class_names:\n",
    "            number_of_matches_per_class=[]\n",
    "\n",
    "            for i in range(TotalImage):\n",
    "                if i!= mainImgNumber and class_name_of_each_rowImg[i]==currentClassName:\n",
    "                    number_of_matches_per_class.append(number_of_matches_between_every_image_with_className[mainImgNumber,i])\n",
    "\n",
    "            number_of_matches_per_class=np.reshape(number_of_matches_per_class,(1,len(number_of_matches_per_class)))\n",
    "            number_of_matches_per_class=number_of_matches_per_class.astype(np.float64)\n",
    "            number_of_matches_per_class.sort(axis=1)\n",
    "            \n",
    "            if k>number_of_matches_per_class.shape[1]:\n",
    "                k=len(number_of_matches_per_class)\n",
    "            else:\n",
    "                k=k_given\n",
    "                \n",
    "            if percentage==True:\n",
    "                k=math.ceil(len(number_of_matches_per_class)*(k_given/100))\n",
    "                    \n",
    "            average_match_wrt_k=np.sum(number_of_matches_per_class[0][-k:])/k\n",
    "            x.append(average_match_wrt_k)\n",
    "            \n",
    "        X.append(x)\n",
    "        Y.append(number_of_matches_between_every_image_with_className[mainImgNumber,TotalImage])\n",
    "    X=np.reshape(X,(TotalImage,len(class_names)))\n",
    "    Y=np.reshape(Y,(TotalImage,1))\n",
    "    #X=np.reshape(X,(1,len(class_names)))\n",
    "    #for cn in range(len(class_names)):\n",
    "        #print(class_names[cn],\" = \",X[0][cn])\n",
    "    #print(Y)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f24e6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "[X,Y]=create_dataset_wrt_k(2,False,number_of_matches_between_every_image_with_className,class_names,class_name_of_each_rowImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e40d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "Y_flatten=Y.flat\n",
    "\n",
    "le.fit(Y_flatten)\n",
    "list(le.classes_)\n",
    "\n",
    "Y_transformed_int=le.transform(Y_flatten)\n",
    "X=np.transpose(X)\n",
    "\n",
    "#le.inverse_transform([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8462e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class LinearClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim=27, output_dim=27):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485724e",
   "metadata": {},
   "source": [
    "#### Information about K-fold:\n",
    "- we will have **K models** in K-fold algorithm\n",
    "    - for each split of training set, train a new model on the training set and then test on testing data\n",
    "    - take mean accuracy over k models\n",
    "- leave one out cross validation (loocv) has low bias, high variance in real world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e2456021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOOCV\n",
    "def LOOCV(X,Y,le):\n",
    "    y_t = torch.from_numpy(np.reshape(Y, (Y.shape[0],1)))\n",
    "    X_t=torch.from_numpy(np.transpose(X))\n",
    "    X_t = X_t.to(torch.float32)\n",
    "\n",
    "    print(\"X = \",X_t.shape)\n",
    "    print(\"Y = \",y_t.shape)\n",
    "\n",
    "\n",
    "    avg_accuracy=0\n",
    "\n",
    "    labels=[]\n",
    "    x_axis=[]\n",
    "    #unique_y=np.reshape(torch.unique(y_t), (torch.unique(y_t).shape[0],1))\n",
    "    for i in range(X_t.shape[1]):\n",
    "        labels.append(le.inverse_transform(y_t[i])[0])\n",
    "        x_axis.append(i)\n",
    "\n",
    "    #print(labels)\n",
    "\n",
    "    class_wise_misclassification = [0]*27\n",
    "    class_wise_n_images=[0]*27\n",
    "\n",
    "    for i in range(X_t.shape[0]):\n",
    "        X_train=torch.cat((X_t[0:i,:],X_t[i+1:,:]),0)\n",
    "        X_test=X_t[i,:]\n",
    "        y_train=torch.cat((y_t[0:i],y_t[i+1:]),0)\n",
    "        y_test=y_t[i]\n",
    "\n",
    "        model = LinearClassifier(2,27)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "        accuracy=0\n",
    "\n",
    "        #train on train data\n",
    "        for epoch in range(1000):\n",
    "            output = model(X_train)\n",
    "\n",
    "            loss = criterion(output, y_train.view(-1))\n",
    "            #print(loss.item())\n",
    "            #all_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        #prediction on test data\n",
    "        result=model.forward(X_test)\n",
    "        predicted=torch.argmax(result)\n",
    "\n",
    "        class_wise_n_images[y_test]=class_wise_n_images[y_test]+1\n",
    "\n",
    "        if predicted == y_test:\n",
    "            accuracy+=1\n",
    "        else:\n",
    "            class_wise_misclassification[y_test]=class_wise_misclassification[y_test]+1\n",
    "            #print(\"Error: predicted label: \",le.inverse_transform([predicted]), \" Actual label: \",le.inverse_transform([y_test[0]]))\n",
    "\n",
    "        avg_accuracy+=accuracy\n",
    "\n",
    "    #plotLOOCV(X_t,class_wise_misclassification,class_wise_n_images,labels,x_axis)\n",
    "    \n",
    "\n",
    "    print(\"Accuracy: \",(avg_accuracy/Y.shape[0])*100,\" % \")\n",
    "    #print(class_wise_misclassification)\n",
    "    \n",
    "    return (avg_accuracy/Y.shape[0])*100,class_wise_misclassification,class_wise_n_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9f49157e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erato_petiverana melpomene_rosina_N\n",
      "X =  torch.Size([53, 2])\n",
      "Y =  torch.Size([53, 1])\n",
      "Accuracy:  66.0377358490566  % \n",
      "erato_petiverana melpomene_rosina_S\n",
      "X =  torch.Size([57, 2])\n",
      "Y =  torch.Size([57, 1])\n",
      "Accuracy:  64.91228070175438  % \n",
      "erato_hydara melpomene_melpomene\n",
      "X =  torch.Size([53, 2])\n",
      "Y =  torch.Size([53, 1])\n",
      "Accuracy:  90.56603773584906  % \n",
      "erato_venus melpomene_vulcanus\n",
      "X =  torch.Size([21, 2])\n",
      "Y =  torch.Size([21, 1])\n",
      "Accuracy:  61.904761904761905  % \n",
      "erato_cyrbia melpomene_cythera\n",
      "X =  torch.Size([25, 2])\n",
      "Y =  torch.Size([25, 1])\n",
      "Accuracy:  76.0  % \n",
      "erato_notabilis melpomene_plesseni\n",
      "X =  torch.Size([41, 2])\n",
      "Y =  torch.Size([41, 1])\n",
      "Accuracy:  65.85365853658537  % \n",
      "erato_etylus melpomene_ecuadorensis\n",
      "X =  torch.Size([13, 2])\n",
      "Y =  torch.Size([13, 1])\n",
      "Accuracy:  69.23076923076923  % \n",
      "erato_emma melpomene_aglaope\n",
      "X =  torch.Size([8, 2])\n",
      "Y =  torch.Size([8, 1])\n",
      "Accuracy:  50.0  % \n",
      "erato_favorinus melpomene_amaryllis\n",
      "X =  torch.Size([12, 2])\n",
      "Y =  torch.Size([12, 1])\n",
      "Accuracy:  41.66666666666667  % \n",
      "erato_microclea melpomene_xenoclea\n",
      "X =  torch.Size([20, 2])\n",
      "Y =  torch.Size([20, 1])\n",
      "Accuracy:  60.0  % \n",
      "erato_luscombei melpomene_schunkei\n",
      "X =  torch.Size([15, 2])\n",
      "Y =  torch.Size([15, 1])\n",
      "Accuracy:  66.66666666666666  % \n",
      "erato_phyllis melpomene_nanna\n",
      "X =  torch.Size([79, 2])\n",
      "Y =  torch.Size([79, 1])\n",
      "Accuracy:  59.49367088607595  % \n"
     ]
    }
   ],
   "source": [
    "#create mimic pairs and run LOOCV\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "\n",
    "table=[[\"Species_1\",\"N_Image\",\"Misclassified_Image\",\"Weighted_error%\",\"Species_2\",\"N_Image\",\"Misclassified_Image\",\"Weighted_error%\",\"Accuracy\"]]\n",
    "with open ('mimic_pairs.csv') as csv_file:\n",
    "    csv_reader=csv.reader(csv_file,delimiter=\",\")\n",
    "    for row in csv_reader:\n",
    "        print(row[0],row[1])\n",
    "        #print(le.transform([row[0]])[0])\n",
    "        [X_m,Y_m]=create_mimic_data(X,Y_transformed_int,le.transform([row[0]])[0],le.transform([row[1]])[0])\n",
    "        #print(X_m.shape, Y_m.shape)\n",
    "        \n",
    "        [accuracy,class_wise_misclassification,class_wise_n_images]=LOOCV(X_m,Y_m,le)\n",
    "        \n",
    "        \n",
    "        row_to_add=[row[0],class_wise_n_images[le.transform([row[0]])[0]]\\\n",
    "                     ,class_wise_misclassification[le.transform([row[0]])[0]],\\\n",
    "                    (class_wise_misclassification[le.transform([row[0]])[0]]/class_wise_n_images[le.transform([row[0]])[0]])*100\\\n",
    "                    , row[1]\\\n",
    "                     ,class_wise_n_images[le.transform([row[1]])[0]],class_wise_misclassification[le.transform([row[1]])[0]],\\\n",
    "                     (class_wise_misclassification[le.transform([row[1]])[0]]/class_wise_n_images[le.transform([row[1]])[0]])*100\\\n",
    "                    ,accuracy]\n",
    "        table.append(row_to_add)\n",
    "    save_t=tabulate(table,headers='keys', tablefmt='firstrow', missingval='N/A')\n",
    "    with open('table.txt', 'w') as f:\n",
    "        f.write(save_t)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d8e9a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mimic_data(X,Y,name_1,name_2):\n",
    "    X_m=[]\n",
    "    Y_m=[]\n",
    "    \n",
    "    n_image=0\n",
    "    \n",
    "    for i in range(Y.shape[0]):\n",
    "        if Y[i]== name_1 or Y[i]== name_2:\n",
    "            n_image=n_image+1\n",
    "            X_m.append(X[[name_1,name_2],i])\n",
    "            Y_m.append(Y[i])\n",
    "    X_m=np.reshape(X_m,(2,n_image))\n",
    "    Y_m=np.reshape(Y_m,(n_image,1))\n",
    "    return X_m,Y_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91e5a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLOOCV(X_t,class_wise_misclassification,class_wise_n_images,labels,x_axis):\n",
    "    plt.axis([0,X_t.shape[1], 0, 61])\n",
    "    plt.bar(x_axis, class_wise_misclassification, color ='blue',width = 0.4)\n",
    "    plt.xticks(x_axis, labels, rotation=90)\n",
    "    plt.ylabel(\"Number of Images\")\n",
    "    plt.xlabel(\"Class Name\")\n",
    "    plt.title(\"Number of misclassified image per class for LOOCV\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.axis([0,X_t.shape[1], 0, 61])\n",
    "    plt.bar(x_axis, class_wise_n_images, color ='green',width = 0.4)\n",
    "    plt.xticks(x_axis, labels, rotation=90)\n",
    "    plt.ylabel(\"Number of Images\")\n",
    "    plt.xlabel(\"Class Name\")\n",
    "    plt.title(\"Number of image per class\")\n",
    "    plt.show()\n",
    "\n",
    "    weighted_error= [(i / j)*100 for i, j in zip(class_wise_misclassification, class_wise_n_images)]\n",
    "    plt.axis([0,X_t.shape[1], 0, 100])\n",
    "    plt.bar(x_axis, weighted_error, color ='maroon',width = 0.4)\n",
    "    plt.xticks(x_axis, labels, rotation=90)\n",
    "    plt.ylabel(\"Number of Images\")\n",
    "    plt.xlabel(\"Class Name\")\n",
    "    plt.title(\"weighted error (misclassified n_images /total n_images) per class\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "069cfa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomTensorDataset(Dataset):\n",
    "    def __init__(self, dataset, transform_list=None):\n",
    "        [data_X, data_y] = dataset\n",
    "        #X_tensor, y_tensor = torch.tensor(data_X), torch.tensor(data_y)\n",
    "        X_tensor, y_tensor= data_X.clone().detach(), data_y.clone().detach()\n",
    "        tensors = (X_tensor, y_tensor)\n",
    "        \n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        \n",
    "        self.tensors = tensors\n",
    "        self.transforms = transform_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[0][index]\n",
    "\n",
    "        if self.transforms:\n",
    "            x = self.transforms(x)\n",
    "\n",
    "        y = self.tensors[1][index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensors[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cba952e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset = [X_train, y_train]\n",
    "#testset = [X_test, y_test]\n",
    "Data_with_label=[X_t,y_t]\n",
    "\n",
    "transforms_list=None\n",
    "\n",
    "if transforms_list:\n",
    "    dataset= CustomTensorDataset(dataset=Data_with_label,transform_list=transforms_list_train)\n",
    "else:\n",
    "    dataset= CustomTensorDataset(dataset=Data_with_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fd926e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "(tensor([ 429.0000,  706.5000,  750.5000,  227.0000,  696.5000,  475.0000,\n",
      "         803.0000,  373.5000,  282.5000,  970.0000,  551.5000, 1008.5000,\n",
      "         282.0000,  461.0000,  659.5000,   65.0000,  183.0000,  639.0000,\n",
      "         389.5000,  668.5000,  528.5000,  705.5000,  734.0000,  475.0000,\n",
      "         301.0000,  375.5000,  439.0000]), tensor([12]))\n",
      "Dataset :  tensor([ 429.0000,  706.5000,  750.5000,  227.0000,  696.5000,  475.0000,\n",
      "         803.0000,  373.5000,  282.5000,  970.0000,  551.5000, 1008.5000,\n",
      "         282.0000,  461.0000,  659.5000,   65.0000,  183.0000,  639.0000,\n",
      "         389.5000,  668.5000,  528.5000,  705.5000,  734.0000,  475.0000,\n",
      "         301.0000,  375.5000,  439.0000])\n",
      "Label :  tensor([12])\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(dataset[0])\n",
    "print(\"Dataset : \",dataset[0][0])\n",
    "print(\"Label : \",dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f00e86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,device,dataloader,loss_fn,optimizer):\n",
    "    train_loss,train_correct=0.0,0\n",
    "    model.train()\n",
    "    \n",
    "    for X_train,y_train in dataloader:\n",
    "        X_train,y_train=X_train.to(device),y_train.to(device)\n",
    "        #print(X_train.shape)\n",
    "        optimizer.zero_grad()\n",
    "        output=model(X_train)\n",
    "        \n",
    "        loss=loss_fn(output, y_train.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * X_train.size(0)\n",
    "        predictions = torch.argmax(output,axis=1)\n",
    "        train_correct += (predictions == y_train.view(-1)).sum().item()\n",
    "\n",
    "    return train_loss,train_correct\n",
    "  \n",
    "def valid_epoch(model,device,dataloader,loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    model.eval()\n",
    "    \n",
    "    for x_test, y_test in dataloader:\n",
    "        \n",
    "        x_test,y_test = x_test.to(device),y_test.to(device)\n",
    "        output = model(x_test)\n",
    "        \n",
    "        loss=loss_fn(output,y_test.view(-1))\n",
    "        \n",
    "        valid_loss+=loss.item()*x_test.size(0)\n",
    "        predictions = torch.argmax(output,axis=1)\n",
    "        val_correct+=(predictions == y_test.view(-1)).sum().item()\n",
    "\n",
    "    return valid_loss,val_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d11f853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs=100000\n",
    "batch_size=384\n",
    "k=15\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "foldperf={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a06bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch:1/100000 AVG Training Acc 0.56 % AVG Test Acc 7.69 %\n",
      "Epoch:101/100000 AVG Training Acc 82.68 % AVG Test Acc 57.69 %\n",
      "Epoch:201/100000 AVG Training Acc 93.30 % AVG Test Acc 65.38 %\n",
      "Epoch:301/100000 AVG Training Acc 94.41 % AVG Test Acc 76.92 %\n",
      "Epoch:401/100000 AVG Training Acc 97.21 % AVG Test Acc 80.77 %\n",
      "Epoch:501/100000 AVG Training Acc 97.77 % AVG Test Acc 76.92 %\n",
      "Epoch:601/100000 AVG Training Acc 97.49 % AVG Test Acc 80.77 %\n",
      "Epoch:701/100000 AVG Training Acc 98.60 % AVG Test Acc 76.92 %\n",
      "Epoch:801/100000 AVG Training Acc 99.16 % AVG Test Acc 76.92 %\n",
      "Fold 2\n",
      "Epoch:1/100000 AVG Training Acc 1.12 % AVG Test Acc 26.92 %\n",
      "Epoch:101/100000 AVG Training Acc 85.75 % AVG Test Acc 80.77 %\n",
      "Epoch:201/100000 AVG Training Acc 92.46 % AVG Test Acc 80.77 %\n",
      "Fold 3\n",
      "Epoch:1/100000 AVG Training Acc 0.00 % AVG Test Acc 19.23 %\n",
      "Epoch:101/100000 AVG Training Acc 79.61 % AVG Test Acc 65.38 %\n",
      "Epoch:201/100000 AVG Training Acc 92.74 % AVG Test Acc 88.46 %\n",
      "Epoch:301/100000 AVG Training Acc 97.49 % AVG Test Acc 80.77 %\n",
      "Epoch:401/100000 AVG Training Acc 92.74 % AVG Test Acc 80.77 %\n",
      "Fold 4\n",
      "Epoch:1/100000 AVG Training Acc 1.68 % AVG Test Acc 3.85 %\n",
      "Epoch:101/100000 AVG Training Acc 84.08 % AVG Test Acc 65.38 %\n",
      "Epoch:201/100000 AVG Training Acc 94.69 % AVG Test Acc 69.23 %\n",
      "Epoch:301/100000 AVG Training Acc 95.53 % AVG Test Acc 73.08 %\n",
      "Epoch:401/100000 AVG Training Acc 98.32 % AVG Test Acc 73.08 %\n",
      "Fold 5\n",
      "Epoch:1/100000 AVG Training Acc 1.12 % AVG Test Acc 15.38 %\n",
      "Epoch:101/100000 AVG Training Acc 87.15 % AVG Test Acc 76.92 %\n",
      "Epoch:201/100000 AVG Training Acc 91.62 % AVG Test Acc 88.46 %\n",
      "Epoch:301/100000 AVG Training Acc 96.93 % AVG Test Acc 92.31 %\n",
      "Epoch:401/100000 AVG Training Acc 97.77 % AVG Test Acc 92.31 %\n",
      "Fold 6\n",
      "Epoch:1/100000 AVG Training Acc 0.56 % AVG Test Acc 26.92 %\n",
      "Epoch:101/100000 AVG Training Acc 74.02 % AVG Test Acc 69.23 %\n",
      "Epoch:201/100000 AVG Training Acc 93.30 % AVG Test Acc 76.92 %\n",
      "Epoch:301/100000 AVG Training Acc 95.81 % AVG Test Acc 80.77 %\n",
      "Epoch:401/100000 AVG Training Acc 96.93 % AVG Test Acc 80.77 %\n",
      "Fold 7\n",
      "Epoch:1/100000 AVG Training Acc 2.23 % AVG Test Acc 3.85 %\n",
      "Epoch:101/100000 AVG Training Acc 78.21 % AVG Test Acc 80.77 %\n",
      "Epoch:201/100000 AVG Training Acc 93.30 % AVG Test Acc 92.31 %\n",
      "Epoch:301/100000 AVG Training Acc 95.53 % AVG Test Acc 96.15 %\n",
      "Epoch:401/100000 AVG Training Acc 96.93 % AVG Test Acc 88.46 %\n",
      "Epoch:501/100000 AVG Training Acc 97.21 % AVG Test Acc 84.62 %\n",
      "Epoch:601/100000 AVG Training Acc 96.93 % AVG Test Acc 84.62 %\n",
      "Fold 8\n",
      "Epoch:1/100000 AVG Training Acc 2.23 % AVG Test Acc 15.38 %\n",
      "Epoch:101/100000 AVG Training Acc 75.14 % AVG Test Acc 61.54 %\n",
      "Epoch:201/100000 AVG Training Acc 96.93 % AVG Test Acc 84.62 %\n",
      "Epoch:301/100000 AVG Training Acc 95.81 % AVG Test Acc 88.46 %\n",
      "Epoch:401/100000 AVG Training Acc 96.93 % AVG Test Acc 88.46 %\n",
      "Fold 9\n",
      "Epoch:1/100000 AVG Training Acc 0.28 % AVG Test Acc 23.08 %\n",
      "Epoch:101/100000 AVG Training Acc 68.72 % AVG Test Acc 80.77 %\n",
      "Epoch:201/100000 AVG Training Acc 91.62 % AVG Test Acc 80.77 %\n",
      "Fold 10\n",
      "Epoch:1/100000 AVG Training Acc 2.51 % AVG Test Acc 20.00 %\n",
      "Epoch:101/100000 AVG Training Acc 71.59 % AVG Test Acc 80.00 %\n",
      "Epoch:201/100000 AVG Training Acc 91.92 % AVG Test Acc 84.00 %\n",
      "Epoch:301/100000 AVG Training Acc 96.10 % AVG Test Acc 96.00 %\n",
      "Epoch:401/100000 AVG Training Acc 96.66 % AVG Test Acc 96.00 %\n",
      "Fold 11\n",
      "Epoch:1/100000 AVG Training Acc 8.08 % AVG Test Acc 16.00 %\n",
      "Epoch:101/100000 AVG Training Acc 69.08 % AVG Test Acc 56.00 %\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "\n",
    "history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "    \n",
    "    model = LinearClassifier()\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    previous_test_acc=0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_correct=train_epoch(model,device,train_loader,criterion,optimizer)\n",
    "        #print(train_loss / len(train_loader.sampler),\" : \",train_correct)\n",
    "        test_loss, test_correct=valid_epoch(model,device,test_loader,criterion)\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "        test_loss = test_loss / len(test_loader.sampler)\n",
    "        test_acc = test_correct / len(test_loader.sampler) * 100\n",
    "            \n",
    "\n",
    "        if epoch%100 ==0:\n",
    "            #print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,num_epochs,train_loss,test_loss,train_acc,test_acc))\n",
    "            print(\"Epoch:{}/{} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,num_epochs,train_acc,test_acc))\n",
    "            if previous_test_acc == test_acc:\n",
    "                #previous_test_acc=previous_test_acc\n",
    "                break\n",
    "            else:\n",
    "                previous_test_acc=test_acc\n",
    "            \n",
    "            \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_acc'].append(test_acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4ef99188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Test Accuracy :  84.92577597840756\n",
      "Avg Train Accuracy :  98.17751528859847\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg Test Accuracy : \",mean(history['test_acc']) )\n",
    "print(\"Avg Train Accuracy : \",mean(history['train_acc']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac082e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[196.34608459472656,\n",
       " 163.61392211914062,\n",
       " 198.8260955810547,\n",
       " 74.64879608154297,\n",
       " 91.2473373413086]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['test_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a076e",
   "metadata": {},
   "source": [
    "#### K fold\n",
    "- for k=10, epoch = 100000, batch size=128\n",
    "    - Avg Test Accuracy :  87.28070175438597\n",
    "    - Avg Train Accuracy :  98.17701264974448\n",
    "- for k=5, epoch = 100000, batch size = 384\n",
    "    - Avg Test Accuracy :  84.11825017088175\n",
    "    - Avg Train Accuracy :  98.56825584838614\n",
    "- for k=5, epoch = 100000, batch size= 128\n",
    "    - Avg Test Accuracy :  87.23171565276827\n",
    "    - Avg Train Accuracy :  99.74025974025975\n",
    "- for k=10, epoch = 100000, batch size= 64\n",
    "    - Avg Test Accuracy :  87.01754385964912\n",
    "    - Avg Train Accuracy :  99.24855491329478\n",
    "- for k=5, epoch = 100000, batch size= 248\n",
    "    - Avg Test Accuracy :  84.11483253588517\n",
    "    - Avg Train Accuracy :  98.69876052286476\n",
    "- for k=10, epoch = 100000, batch size= 248\n",
    "    - Avg Test Accuracy :  87.53036437246963\n",
    "    - Avg Train Accuracy :  98.00251319426992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c16f44d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
